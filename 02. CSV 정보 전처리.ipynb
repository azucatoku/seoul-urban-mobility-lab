{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56aa977b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import dbconnect # 제공해주신 DB 연결 모듈 사용\n",
    "import sys\n",
    "\n",
    "\n",
    "# 파일 경로 설정 (사용자 환경)\n",
    "\n",
    "BASE_DIR = r\"C:\\Users\\Admin\\Desktop\\hdc2\\00. 프로젝트\\02. 프로젝트 구축\"\n",
    "CSV_DIR = os.path.join(BASE_DIR, \"csv\")\n",
    "\n",
    "# 매핑 파일 경로\n",
    "MAPPING_FILE = os.path.join(BASE_DIR, \"station_master_mapping.csv\")\n",
    "\n",
    "# 처리할 파일 목록 (순서대로 22 -> 23 -> 24)\n",
    "TARGET_FILES = [\n",
    "    os.path.join(CSV_DIR, \"서울교통공사_역별 일별 시간대별 노인 승하차인원_2022.csv\"),\n",
    "    os.path.join(CSV_DIR, \"서울교통공사_일별 역별 시간대별 노인 승하차인원_2023.csv\"),\n",
    "    os.path.join(CSV_DIR, \"서울교통공사_역별 일별 시간대별 노인 승하차인원_2024.csv\")\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0c20869",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 호선 매핑 데이터 로드 함수\n",
    "\n",
    "def load_mapping_table():\n",
    "    \n",
    "    df_map = pd.read_csv(MAPPING_FILE, encoding='utf-8')\n",
    "    \n",
    "    # Merge를 위해 stnCd를 문자열로 통일\n",
    "    df_map['stnCd'] = df_map['stnCd'].astype(str).str.strip() # str.strip()는 공백(스페이스나 탭)을 제거\n",
    "    \n",
    "    # 필요한 컬럼만 리턴 (역코드, 호선명)\n",
    "    return df_map[['stnCd', 'lineNm']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd220034",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터 변환용 함수 정의\n",
    "\n",
    "\n",
    "# 메인 함수 정의 \n",
    "\n",
    "def process_file(file_path, df_mapping):\n",
    "    \n",
    "    # (1) CSV 로드\n",
    "    try:\n",
    "        df_raw = pd.read_csv(file_path, encoding='utf-8')\n",
    "    except:\n",
    "        df_raw = pd.read_csv(file_path, encoding='cp949')\n",
    "        \n",
    "    # (2) 컬럼명 매핑 (API에서 가져온 데이터 컬럼 이름으로 변경)\n",
    "    rename_map = {\n",
    "        '수송일자': 'pasngDe',\n",
    "        '역번호': 'stnCd',\n",
    "        '역명': 'stnNm',\n",
    "        '승하차구분': 'type'\n",
    "    }\n",
    "    df_raw.rename(columns=rename_map, inplace=True)\n",
    "    \n",
    "    # (3) [Mapping] 호선명 채우기\n",
    "    # 원본 CSV의 stnCd도 문자열로 변환하여 매칭 확률 높임\n",
    "    df_raw['stnCd'] = df_raw['stnCd'].astype(str).str.strip()\n",
    "\n",
    "    # Left Join 수행\n",
    "    df_merged = pd.merge(df_raw, df_mapping, on='stnCd', how='left')\n",
    "    \n",
    "    # 매핑 안 된 역은 '정보없음' 처리\n",
    "    df_merged['lineNm'] = df_merged['lineNm'].fillna('정보없음')\n",
    "    \n",
    "    # (4) Melt\n",
    "    # id_vars에 lineNm 포함\n",
    "    id_vars = ['pasngDe', 'stnCd', 'stnNm', 'type', 'lineNm']\n",
    "        \n",
    "    # 시간대 컬럼 자동 탐지\n",
    "    value_vars = []  # 1. 빈 리스트를 하나 만듭니다.\n",
    "\n",
    "    for col in df_merged.columns:      # 2. 전체 컬럼 이름을 하나씩 꺼내서 확인합니다.\n",
    "        if '시간대' in col:            # 3. 만약 이름 안에 '시간대'라는 글자가 있다면?\n",
    "            value_vars.append(col)     # 4. 리스트에 추가합니다.\n",
    "            \n",
    "    \n",
    "    df_melted = df_merged.melt(\n",
    "        id_vars=id_vars,\n",
    "        value_vars=value_vars,\n",
    "        var_name='temp_hr',\n",
    "        value_name='count'\n",
    "    )\n",
    "    \n",
    "    # (5) 시간대 변환\n",
    "    def convert_hour(hr_str):\n",
    "        if '06시간대이전' in hr_str: return 5\n",
    "        elif '24시간대이후' in hr_str: return 0\n",
    "        else:\n",
    "            try:\n",
    "                return int(hr_str.split('-')[0])\n",
    "            except:\n",
    "                return -1\n",
    "\n",
    "    df_melted['pasngHr'] = df_melted['temp_hr'].apply(convert_hour)\n",
    "    \n",
    "    # (6) Pivot (승/하차 분리)\n",
    "    df_pivot = df_melted.pivot_table(\n",
    "        index=['pasngDe', 'pasngHr', 'lineNm', 'stnCd', 'stnNm'],\n",
    "        columns='type',\n",
    "        values='count',\n",
    "        fill_value=0\n",
    "    ).reset_index()\n",
    "    \n",
    "    df_pivot.rename(columns={'승차': 'rideNope', '하차': 'gffNope'}, inplace=True)\n",
    "    df_pivot.columns.name = None\n",
    "    \n",
    "    # (7) 메타데이터 추가\n",
    "    df_pivot['UserGroup'] = '노인/약자'\n",
    "    df_pivot['trnscdUserSeCd'] = '06'\n",
    "    # 날짜 포맷 정리 (2022-01-01 -> 20220101)\n",
    "    df_pivot['pasngDe'] = df_pivot['pasngDe'].astype(str).str.replace('-', '')\n",
    "    \n",
    "    # 최종 컬럼 순서\n",
    "    target_cols = [\n",
    "        'UserGroup', 'pasngDe', 'pasngHr', 'lineNm', \n",
    "        'stnCd', 'stnNm', 'trnscdUserSeCd', \n",
    "        'rideNope', 'gffNope'\n",
    "    ]\n",
    "    \n",
    "    return df_pivot[target_cols]\n",
    "\n",
    "\n",
    "# 적재 함수 정의\n",
    "\n",
    "def insert_to_db(conn, df):\n",
    "    cursor = conn.cursor()\n",
    "    \n",
    "    # 1. 사용할 컬럼 목록을 리스트로 명확히 정의합니다.\n",
    "    # (DataFrame에서 이 순서대로 데이터를 뽑아냅니다)\n",
    "    columns = [\n",
    "        'UserGroup', 'pasngDe', 'pasngHr', 'lineNm', \n",
    "        'stnCd', 'stnNm', 'trnscdUserSeCd', 'rideNope', 'gffNope'\n",
    "    ]\n",
    "    \n",
    "    # 2. SQL 쿼리 작성\n",
    "    # 테이블명에 하이픈(-)이 있으므로 반드시 백틱(`)으로 감싸줍니다.\n",
    "    sql = \"\"\"\n",
    "    INSERT INTO `subway_traffic_log_senior_22-24`\n",
    "    (UserGroup, pasngDe, pasngHr, lineNm, stnCd, stnNm, trnscdUserSeCd, rideNope, gffNope)\n",
    "    VALUES (%s, %s, %s, %s, %s, %s, %s, %s, %s)\n",
    "    ON DUPLICATE KEY UPDATE\n",
    "        rideNope = VALUES(rideNope),\n",
    "        gffNope = VALUES(gffNope)\n",
    "    \"\"\"\n",
    "    \n",
    "    # 3. 데이터프레임에서 위에서 정한 컬럼들만 뽑아 값을 가져옵니다.\n",
    "    # raw_data는 리스트의 리스트 형태가 됩니다.\n",
    "    raw_data = df[columns].values\n",
    "    \n",
    "    count = 0\n",
    "    \n",
    "    # 4. 한 줄씩 꺼내서 반복문(Loop) 실행\n",
    "    for row in raw_data:\n",
    "        try:\n",
    "            # row는 하나의 행 데이터입니다. (인덱스 0부터 8까지 존재)\n",
    "            # 안전하게 넣기 위해 숫자는 int()로 명확히 변환해줍니다.\n",
    "            data = (\n",
    "                row[0],          # UserGroup\n",
    "                row[1],          # pasngDe\n",
    "                int(row[2]),     # pasngHr (시간은 숫자)\n",
    "                row[3],          # lineNm\n",
    "                row[4],          # stnCd\n",
    "                row[5],          # stnNm\n",
    "                row[6],          # trnscdUserSeCd\n",
    "                int(row[7]),     # rideNope (인원수는 숫자)\n",
    "                int(row[8])      # gffNope (인원수는 숫자)\n",
    "            )\n",
    "            \n",
    "            # 한 줄 실행 (여기서 에러가 나면 해당 줄만 건너뜀)\n",
    "            cursor.execute(sql, data)\n",
    "            count += 1\n",
    "            \n",
    "        except Exception as e:\n",
    "            # 어떤 데이터에서 에러가 났는지 출력해서 확인 가능\n",
    "            print(f\"에러: {e}\")\n",
    "            print(f\"문제 데이터: {row}\")\n",
    "            \n",
    "    # 5. 모든 반복이 끝나면 최종 저장(Commit)\n",
    "    try:\n",
    "        conn.commit()\n",
    "        print(f\"총 {count}건 저장 완료\")\n",
    "        return count\n",
    "    except Exception as e:\n",
    "        print(f\"에러: {e}\")\n",
    "        conn.rollback()\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "947fa961",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 메인 실행 블록\n",
    "\n",
    "\n",
    "# 1. 매핑 테이블 준비\n",
    "df_mapping = load_mapping_table()\n",
    "    \n",
    "# 2. DB 연결\n",
    "conn = dbconnect.MydbConnect('seoul_urban_lab')\n",
    "    \n",
    "total_processed = 0\n",
    "    \n",
    "# 3. 파일별 순차 처리 (2022 -> 2023 -> 2024)\n",
    "for file_path in TARGET_FILES:\n",
    "            \n",
    "    # 변환\n",
    "    df_final = process_file(file_path, df_mapping)\n",
    "    print(f\"변환 완료: {len(df_final)}행\")\n",
    "        \n",
    "    # 적재 (10000개씩 끊어서 넣기 - 메모리 보호)\n",
    "    CHUNK_SIZE = 10000\n",
    "    file_inserted_count = 0\n",
    "        \n",
    "    print(\"DB 적재 시작\")\n",
    "    for i in range(0, len(df_final), CHUNK_SIZE):\n",
    "        chunk = df_final.iloc[i:i+CHUNK_SIZE]\n",
    "        cnt = insert_to_db(conn, chunk)\n",
    "        file_inserted_count += cnt\n",
    "        print(f\"      - {i + cnt} / {len(df_final)} 완료\", end=\"\\r\")\n",
    "            \n",
    "    print(f\"\\n    {os.path.basename(file_path)} 적재 완료! (+{file_inserted_count}건)\")\n",
    "    total_processed += file_inserted_count\n",
    "        \n",
    "conn.close()\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(f\"모든 작업 완료! 총 {total_processed}건의 데이터가 DB에 저장되었습니다.\")\n",
    "print(\"=\"*50)\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
