{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bd80d133",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… CSV íŒŒì¼ ë¡œë“œ ì„±ê³µ\n",
      "\n",
      "ğŸ“Š [ë³€í™˜ ê²°ê³¼ ë¯¸ë¦¬ë³´ê¸°] station_meta í…Œì´ë¸” ì ì¬ìš©\n",
      "============================================================\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>stnCd</th>\n",
       "      <th>stnNm</th>\n",
       "      <th>lineNm</th>\n",
       "      <th>lat</th>\n",
       "      <th>lon</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>150</td>\n",
       "      <td>ì„œìš¸</td>\n",
       "      <td>1í˜¸ì„ </td>\n",
       "      <td>37.553150</td>\n",
       "      <td>126.972533</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>151</td>\n",
       "      <td>ì‹œì²­</td>\n",
       "      <td>1í˜¸ì„ </td>\n",
       "      <td>37.563590</td>\n",
       "      <td>126.975407</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>152</td>\n",
       "      <td>ì¢…ê°</td>\n",
       "      <td>1í˜¸ì„ </td>\n",
       "      <td>37.570203</td>\n",
       "      <td>126.983116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>153</td>\n",
       "      <td>ì¢…ë¡œ3ê°€</td>\n",
       "      <td>1í˜¸ì„ </td>\n",
       "      <td>37.570429</td>\n",
       "      <td>126.992095</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>154</td>\n",
       "      <td>ì¢…ë¡œ5ê°€</td>\n",
       "      <td>1í˜¸ì„ </td>\n",
       "      <td>37.570971</td>\n",
       "      <td>127.001900</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  stnCd stnNm lineNm        lat         lon\n",
       "0   150    ì„œìš¸    1í˜¸ì„   37.553150  126.972533\n",
       "1   151    ì‹œì²­    1í˜¸ì„   37.563590  126.975407\n",
       "2   152    ì¢…ê°    1í˜¸ì„   37.570203  126.983116\n",
       "3   153  ì¢…ë¡œ3ê°€    1í˜¸ì„   37.570429  126.992095\n",
       "4   154  ì¢…ë¡œ5ê°€    1í˜¸ì„   37.570971  127.001900"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------------\n",
      "ì´ ë°ì´í„° ê±´ìˆ˜: 276ê°œ\n",
      "ì´ í˜•íƒœ ê·¸ëŒ€ë¡œ DBì— ì ì¬í•˜ë©´ 'ì—­ì½”ë“œ(stnCd)'ë¥¼ ê¸°ì¤€ìœ¼ë¡œ ì¡°ì¸í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# 1. íŒŒì¼ ê²½ë¡œ ì„¤ì •\n",
    "file_path = 'ì„œìš¸êµí†µê³µì‚¬_1_8í˜¸ì„  ì—­ì‚¬ ì¢Œí‘œ(ìœ„ê²½ë„) ì •ë³´_20250814.csv'\n",
    "\n",
    "# 2. CSV íŒŒì¼ ë¡œë“œ\n",
    "try:\n",
    "    df_raw = pd.read_csv(file_path, encoding='utf-8')\n",
    "except UnicodeDecodeError:\n",
    "    df_raw = pd.read_csv(file_path, encoding='cp949')\n",
    "\n",
    "print(\"âœ… CSV íŒŒì¼ ë¡œë“œ ì„±ê³µ\")\n",
    "\n",
    "# 3. ë°ì´í„° ì „ì²˜ë¦¬ (Transform)\n",
    "# (1) ì»¬ëŸ¼ëª… ë§¤í•‘\n",
    "rename_map = {\n",
    "    'ê³ ìœ ì—­ë²ˆí˜¸(ì™¸ë¶€ì—­ì½”ë“œ)': 'stnCd',\n",
    "    'ì—­ëª…': 'stnNm',\n",
    "    'ìœ„ë„': 'lat',\n",
    "    'ê²½ë„': 'lon'\n",
    "}\n",
    "df_raw.rename(columns=rename_map, inplace=True)\n",
    "\n",
    "# (2) í˜¸ì„ ëª… í¬ë§· í†µì¼ (1 -> 1í˜¸ì„ )\n",
    "# ê¸°ì¡´ DBì˜ lineNm ì»¬ëŸ¼ê³¼ ì¡°ì¸í•˜ê¸° ìœ„í•´ í•„ìˆ˜ì ì¸ ë‹¨ê³„ì…ë‹ˆë‹¤.\n",
    "if 'í˜¸ì„ ' in df_raw.columns:\n",
    "    df_raw['lineNm'] = df_raw['í˜¸ì„ '].astype(str).apply(lambda x: x + 'í˜¸ì„ ' if x.isdigit() else x)\n",
    "else:\n",
    "    df_raw['lineNm'] = 'ì •ë³´ì—†ìŒ'\n",
    "\n",
    "# (3) ì—­ì½”ë“œ ë¬¸ìì—´ ë³€í™˜ (DB íƒ€ì… ë§¤ì¹­)\n",
    "df_raw['stnCd'] = df_raw['stnCd'].astype(str).str.strip()\n",
    "\n",
    "# (4) ìµœì¢… ì»¬ëŸ¼ ì„ íƒ\n",
    "target_cols = ['stnCd', 'stnNm', 'lineNm', 'lat', 'lon']\n",
    "df_final = df_raw[target_cols].copy()\n",
    "\n",
    "# 4. ê²°ê³¼ í™•ì¸ (ìƒìœ„ 5ê°œ)\n",
    "print(\"\\nğŸ“Š [ë³€í™˜ ê²°ê³¼ ë¯¸ë¦¬ë³´ê¸°] station_meta í…Œì´ë¸” ì ì¬ìš©\")\n",
    "print(\"=\"*60)\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.width', 1000)\n",
    "\n",
    "display(df_final.head(5))\n",
    "\n",
    "print(\"-\" * 60)\n",
    "print(f\"ì´ ë°ì´í„° ê±´ìˆ˜: {len(df_final)}ê°œ\")\n",
    "print(\"ì´ í˜•íƒœ ê·¸ëŒ€ë¡œ DBì— ì ì¬í•˜ë©´ 'ì—­ì½”ë“œ(stnCd)'ë¥¼ ê¸°ì¤€ìœ¼ë¡œ ì¡°ì¸í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6b6cbe16",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“‚ íŒŒì¼ ë¡œë“œ ì¤‘... (ì„œìš¸êµí†µê³µì‚¬_1_8í˜¸ì„  ì—­ì‚¬ ì¢Œí‘œ(ìœ„ê²½ë„) ì •ë³´_20250814.csv)\n",
      "   -> ë³€í™˜ ì™„ë£Œ: 276í–‰\n",
      "\n",
      "ğŸ”Œ DB ì—°ê²° ì‹œë„...\n",
      "ë°ì´í„°ë² ì´ì„œ ì—°ê²° ì‹œì‘!\n",
      "MySQL DB ì—°ê²° ì„±ê³µ\n",
      "âœ… DB ì ì¬ ì„±ê³µ! (ì´ 276ê±´ ì²˜ë¦¬)\n",
      "\n",
      "ğŸ‰ ì—­ì‚¬ ì¢Œí‘œ ë§ˆìŠ¤í„° ë°ì´í„° êµ¬ì¶• ì™„ë£Œ.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import dbconnect\n",
    "import os\n",
    "import sys\n",
    "\n",
    "# ---------------------------------------------------------\n",
    "# 1. ì„¤ì • ë° íŒŒì¼ ë¡œë“œ\n",
    "# ---------------------------------------------------------\n",
    "FILE_NAME = 'ì„œìš¸êµí†µê³µì‚¬_1_8í˜¸ì„  ì—­ì‚¬ ì¢Œí‘œ(ìœ„ê²½ë„) ì •ë³´_20250814.csv'\n",
    "\n",
    "def load_and_transform_csv():\n",
    "    \"\"\"CSV íŒŒì¼ì„ ì½ì–´ DB ì ì¬ í¬ë§·ìœ¼ë¡œ ë³€í™˜\"\"\"\n",
    "    if not os.path.exists(FILE_NAME):\n",
    "        print(f\"âŒ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {FILE_NAME}\")\n",
    "        sys.exit()\n",
    "\n",
    "    print(f\"ğŸ“‚ íŒŒì¼ ë¡œë“œ ì¤‘... ({FILE_NAME})\")\n",
    "    try:\n",
    "        df = pd.read_csv(FILE_NAME, encoding='utf-8')\n",
    "    except UnicodeDecodeError:\n",
    "        df = pd.read_csv(FILE_NAME, encoding='cp949')\n",
    "\n",
    "    # (1) ì»¬ëŸ¼ëª… ë§¤í•‘\n",
    "    rename_map = {\n",
    "        'ê³ ìœ ì—­ë²ˆí˜¸(ì™¸ë¶€ì—­ì½”ë“œ)': 'stnCd',\n",
    "        'ì—­ëª…': 'stnNm',\n",
    "        'ìœ„ë„': 'lat',\n",
    "        'ê²½ë„': 'lon'\n",
    "    }\n",
    "    df.rename(columns=rename_map, inplace=True)\n",
    "\n",
    "    # (2) í˜¸ì„ ëª… ë³€í™˜ (ì˜ˆ: 1 -> 1í˜¸ì„ )\n",
    "    # í˜¸ì„  ì •ë³´ê°€ ì—†ê±°ë‚˜ ë¹„ì–´ìˆì„ ê²½ìš° ëŒ€ë¹„\n",
    "    if 'í˜¸ì„ ' in df.columns:\n",
    "        df['lineNm'] = df['í˜¸ì„ '].astype(str).apply(lambda x: x + 'í˜¸ì„ ' if x.isdigit() else x)\n",
    "    else:\n",
    "        print(\"âš ï¸ 'í˜¸ì„ ' ì»¬ëŸ¼ì´ ì—†ì–´ 'ì •ë³´ì—†ìŒ'ìœ¼ë¡œ ì²˜ë¦¬í•©ë‹ˆë‹¤.\")\n",
    "        df['lineNm'] = 'ì •ë³´ì—†ìŒ'\n",
    "\n",
    "    # (3) ë°ì´í„° íƒ€ì… ì •ë¦¬ (DB ìŠ¤í‚¤ë§ˆ ë§¤ì¹­)\n",
    "    df['stnCd'] = df['stnCd'].astype(str).str.strip()\n",
    "    df['stnNm'] = df['stnNm'].astype(str).str.strip()\n",
    "    df['lat'] = pd.to_numeric(df['lat'], errors='coerce')\n",
    "    df['lon'] = pd.to_numeric(df['lon'], errors='coerce')\n",
    "\n",
    "    # (4) ê²°ì¸¡ì¹˜ ì œê±° (ì¢Œí‘œê°€ ì—†ëŠ” ê²½ìš° ì œì™¸)\n",
    "    df_clean = df.dropna(subset=['lat', 'lon', 'stnCd'])\n",
    "    \n",
    "    # (5) ìµœì¢… ì»¬ëŸ¼ ì„ íƒ\n",
    "    target_cols = ['stnCd', 'stnNm', 'lineNm', 'lat', 'lon']\n",
    "    return df_clean[target_cols]\n",
    "\n",
    "# ---------------------------------------------------------\n",
    "# 2. DB ì ì¬ í•¨ìˆ˜\n",
    "# ---------------------------------------------------------\n",
    "def insert_meta_data(conn, df):\n",
    "    \"\"\"ë³€í™˜ëœ ë°ì´í„°ë¥¼ station_meta í…Œì´ë¸”ì— Insert/Update\"\"\"\n",
    "    if df.empty:\n",
    "        print(\"âš ï¸ ì ì¬í•  ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.\")\n",
    "        return\n",
    "\n",
    "    cursor = conn.cursor()\n",
    "    \n",
    "    # Upsert ì¿¼ë¦¬: ì´ë¯¸ ì¡´ì¬í•˜ëŠ” ì—­(stnCd ê¸°ì¤€)ì´ë©´ ì¢Œí‘œì™€ ì´ë¦„ì„ ìµœì‹ ìœ¼ë¡œ ì—…ë°ì´íŠ¸\n",
    "    sql = \"\"\"\n",
    "        INSERT INTO station_meta (stnCd, stnNm, lineNm, lat, lon)\n",
    "        VALUES (%s, %s, %s, %s, %s)\n",
    "        ON DUPLICATE KEY UPDATE\n",
    "            stnNm = VALUES(stnNm),\n",
    "            lineNm = VALUES(lineNm),\n",
    "            lat = VALUES(lat),\n",
    "            lon = VALUES(lon),\n",
    "            created_at = NOW()\n",
    "    \"\"\"\n",
    "\n",
    "    # DataFrameì„ íŠœí”Œ ë¦¬ìŠ¤íŠ¸ë¡œ ë³€í™˜\n",
    "    data_tuples = [tuple(x) for x in df.to_numpy()]\n",
    "    \n",
    "    try:\n",
    "        cursor.executemany(sql, data_tuples)\n",
    "        conn.commit()\n",
    "        print(f\"âœ… DB ì ì¬ ì„±ê³µ! (ì´ {len(data_tuples)}ê±´ ì²˜ë¦¬)\")\n",
    "    except Exception as e:\n",
    "        print(f\"âŒ DB ì ì¬ ì‹¤íŒ¨: {e}\")\n",
    "        conn.rollback()\n",
    "\n",
    "# ---------------------------------------------------------\n",
    "# 3. ë©”ì¸ ì‹¤í–‰\n",
    "# ---------------------------------------------------------\n",
    "if __name__ == \"__main__\":\n",
    "    # 1. ë°ì´í„° ì¤€ë¹„\n",
    "    df_result = load_and_transform_csv()\n",
    "    print(f\"   -> ë³€í™˜ ì™„ë£Œ: {len(df_result)}í–‰\")\n",
    "\n",
    "    # 2. DB ì—°ê²°\n",
    "    print(\"\\nğŸ”Œ DB ì—°ê²° ì‹œë„...\")\n",
    "    conn = dbconnect.MydbConnect('seoul_urban_lab')\n",
    "\n",
    "    # 3. ì ì¬ ì‹¤í–‰\n",
    "    insert_meta_data(conn, df_result)\n",
    "\n",
    "    # 4. ì—°ê²° ì¢…ë£Œ\n",
    "    conn.close()\n",
    "    print(\"\\nğŸ‰ ì—­ì‚¬ ì¢Œí‘œ ë§ˆìŠ¤í„° ë°ì´í„° êµ¬ì¶• ì™„ë£Œ.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5cad99f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“‚ íŒŒì¼ ë¡œë“œ ë° í¬ë§· êµì • ì¤‘... (ì„œìš¸êµí†µê³µì‚¬_1_8í˜¸ì„  ì—­ì‚¬ ì¢Œí‘œ(ìœ„ê²½ë„) ì •ë³´_20250814.csv)\n",
      "   -> ë³€í™˜ëœ 1í˜¸ì„  ì½”ë“œ ì˜ˆì‹œ: 0150 (4ìë¦¬ì—¬ì•¼ í•¨)\n",
      "ë°ì´í„°ë² ì´ì„œ ì—°ê²° ì‹œì‘!\n",
      "MySQL DB ì—°ê²° ì„±ê³µ\n",
      "âœ… DB ì ì¬ ì„±ê³µ! (ì´ 276ê±´)\n",
      "\n",
      "ğŸ” [ê²€ì¦] 1í˜¸ì„ (ì„œìš¸ì—­) ì½”ë“œê°€ '0150'ìœ¼ë¡œ ì˜ ë“¤ì–´ê°”ëŠ”ì§€ í™•ì¸:\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import dbconnect\n",
    "import os\n",
    "import sys\n",
    "\n",
    "# ---------------------------------------------------------\n",
    "# 1. ì„¤ì • ë° íŒŒì¼ ë¡œë“œ\n",
    "# ---------------------------------------------------------\n",
    "FILE_NAME = 'ì„œìš¸êµí†µê³µì‚¬_1_8í˜¸ì„  ì—­ì‚¬ ì¢Œí‘œ(ìœ„ê²½ë„) ì •ë³´_20250814.csv'\n",
    "\n",
    "def load_and_transform_csv_v2():\n",
    "    if not os.path.exists(FILE_NAME):\n",
    "        print(f\"âŒ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {FILE_NAME}\")\n",
    "        sys.exit()\n",
    "\n",
    "    print(f\"ğŸ“‚ íŒŒì¼ ë¡œë“œ ë° í¬ë§· êµì • ì¤‘... ({FILE_NAME})\")\n",
    "    try:\n",
    "        df = pd.read_csv(FILE_NAME, encoding='utf-8')\n",
    "    except UnicodeDecodeError:\n",
    "        df = pd.read_csv(FILE_NAME, encoding='cp949')\n",
    "\n",
    "    # (1) ì»¬ëŸ¼ëª… ë§¤í•‘\n",
    "    rename_map = {\n",
    "        'ê³ ìœ ì—­ë²ˆí˜¸(ì™¸ë¶€ì—­ì½”ë“œ)': 'stnCd',\n",
    "        'ì—­ëª…': 'stnNm',\n",
    "        'ìœ„ë„': 'lat',\n",
    "        'ê²½ë„': 'lon'\n",
    "    }\n",
    "    df.rename(columns=rename_map, inplace=True)\n",
    "\n",
    "    # (2) í˜¸ì„ ëª… ë³€í™˜ (1 -> 1í˜¸ì„ )\n",
    "    if 'í˜¸ì„ ' in df.columns:\n",
    "        df['lineNm'] = df['í˜¸ì„ '].astype(str).apply(lambda x: x + 'í˜¸ì„ ' if x.isdigit() else x)\n",
    "    else:\n",
    "        df['lineNm'] = 'ì •ë³´ì—†ìŒ'\n",
    "\n",
    "    # ---------------------------------------------------------\n",
    "    # ğŸš¨ [í•µì‹¬ ìˆ˜ì • ì‚¬í•­] ì—­ì½”ë“œ 4ìë¦¬ íŒ¨ë”© (Zero Padding)\n",
    "    # ---------------------------------------------------------\n",
    "    # API ë°ì´í„°ëŠ” '0150' í˜•ì‹ì´ë¯€ë¡œ, CSVì˜ '150'ì„ '0150'ìœ¼ë¡œ ë§ì¶°ì¤ë‹ˆë‹¤.\n",
    "    df['stnCd'] = df['stnCd'].astype(str).str.strip().str.zfill(4)\n",
    "    \n",
    "    # stnNm ê³µë°± ì œê±°\n",
    "    df['stnNm'] = df['stnNm'].astype(str).str.strip()\n",
    "\n",
    "    # ì¢Œí‘œ ë°ì´í„° ìˆ«ì ë³€í™˜\n",
    "    df['lat'] = pd.to_numeric(df['lat'], errors='coerce')\n",
    "    df['lon'] = pd.to_numeric(df['lon'], errors='coerce')\n",
    "\n",
    "    # ê²°ì¸¡ì¹˜ ì œê±°\n",
    "    df_clean = df.dropna(subset=['lat', 'lon', 'stnCd'])\n",
    "    \n",
    "    target_cols = ['stnCd', 'stnNm', 'lineNm', 'lat', 'lon']\n",
    "    return df_clean[target_cols]\n",
    "\n",
    "# ---------------------------------------------------------\n",
    "# 2. DB ì ì¬ í•¨ìˆ˜\n",
    "# ---------------------------------------------------------\n",
    "def insert_meta_data(conn, df):\n",
    "    if df.empty:\n",
    "        return\n",
    "\n",
    "    cursor = conn.cursor()\n",
    "    \n",
    "    # ì´ë¯¸ ë“¤ì–´ê°„ 3ìë¦¬ ì½”ë“œ ë°ì´í„°ê°€ ìˆë‹¤ë©´ ë®ì–´ì“°ê±°ë‚˜, \n",
    "    # ê¹”ë”í•˜ê²Œ í•˜ê¸° ìœ„í•´ TRUNCATE(ë¹„ìš°ê¸°) í›„ ë‹¤ì‹œ ë„£ëŠ” ê²ƒì„ ì¶”ì²œí•©ë‹ˆë‹¤.\n",
    "    # ì—¬ê¸°ì„œëŠ” ON DUPLICATE KEY UPDATEë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤.\n",
    "    sql = \"\"\"\n",
    "        INSERT INTO station_meta (stnCd, stnNm, lineNm, lat, lon)\n",
    "        VALUES (%s, %s, %s, %s, %s)\n",
    "        ON DUPLICATE KEY UPDATE\n",
    "            stnNm = VALUES(stnNm),\n",
    "            lineNm = VALUES(lineNm),\n",
    "            lat = VALUES(lat),\n",
    "            lon = VALUES(lon),\n",
    "            created_at = NOW()\n",
    "    \"\"\"\n",
    "    \n",
    "    data_tuples = [tuple(x) for x in df.to_numpy()]\n",
    "    \n",
    "    try:\n",
    "        cursor.executemany(sql, data_tuples)\n",
    "        conn.commit()\n",
    "        print(f\"âœ… DB ì ì¬ ì„±ê³µ! (ì´ {len(data_tuples)}ê±´)\")\n",
    "        \n",
    "        # 1í˜¸ì„  ìƒ˜í”Œ í™•ì¸\n",
    "        print(\"\\nğŸ” [ê²€ì¦] 1í˜¸ì„ (ì„œìš¸ì—­) ì½”ë“œê°€ '0150'ìœ¼ë¡œ ì˜ ë“¤ì–´ê°”ëŠ”ì§€ í™•ì¸:\")\n",
    "        cursor.execute(\"SELECT * FROM station_meta WHERE stnNm = 'ì„œìš¸ì—­' LIMIT 1\")\n",
    "        print(cursor.fetchone())\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"âŒ DB ì ì¬ ì‹¤íŒ¨: {e}\")\n",
    "        conn.rollback()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # ë°ì´í„° ë³€í™˜\n",
    "    df_result = load_and_transform_csv_v2()\n",
    "    \n",
    "    # ë¯¸ë¦¬ë³´ê¸° í™•ì¸\n",
    "    print(f\"   -> ë³€í™˜ëœ 1í˜¸ì„  ì½”ë“œ ì˜ˆì‹œ: {df_result.iloc[0]['stnCd']} (4ìë¦¬ì—¬ì•¼ í•¨)\")\n",
    "\n",
    "    # DB ì—°ê²° ë° ì ì¬\n",
    "    conn = dbconnect.MydbConnect('seoul_urban_lab')\n",
    "    insert_meta_data(conn, df_result)\n",
    "    conn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b20bbc69",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“‚ ì›ë³¸ íŒŒì¼ ë¡œë“œ ì¤‘... (ì„œìš¸êµí†µê³µì‚¬_1_8í˜¸ì„  ì—­ì‚¬ ì¢Œí‘œ(ìœ„ê²½ë„) ì •ë³´_20250814.csv)\n",
      "ë°ì´í„°ë² ì´ì„œ ì—°ê²° ì‹œì‘!\n",
      "MySQL DB ì—°ê²° ì„±ê³µ\n",
      "ğŸ§¹ ê¸°ì¡´ station_meta í…Œì´ë¸”ì„ ë¹„ìš°ëŠ” ì¤‘ (TRUNCATE)...\n",
      "ğŸ“¥ ì›ë³¸ ë°ì´í„° ì ì¬ ì‹œì‘...\n",
      "âœ… ì›ìƒ ë³µêµ¬ ì™„ë£Œ! (ì´ 276ê±´)\n",
      "\n",
      "ğŸ” [ê²€ì¦] ì„œìš¸ì—­ ì½”ë“œê°€ '150'ìœ¼ë¡œ ëŒì•„ì™”ëŠ”ì§€ í™•ì¸:\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import dbconnect\n",
    "import os\n",
    "import sys\n",
    "\n",
    "# ---------------------------------------------------------\n",
    "# 1. ì„¤ì • ë° íŒŒì¼ ë¡œë“œ\n",
    "# ---------------------------------------------------------\n",
    "FILE_NAME = 'ì„œìš¸êµí†µê³µì‚¬_1_8í˜¸ì„  ì—­ì‚¬ ì¢Œí‘œ(ìœ„ê²½ë„) ì •ë³´_20250814.csv'\n",
    "\n",
    "def load_original_csv():\n",
    "    if not os.path.exists(FILE_NAME):\n",
    "        print(f\"âŒ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {FILE_NAME}\")\n",
    "        sys.exit()\n",
    "\n",
    "    print(f\"ğŸ“‚ ì›ë³¸ íŒŒì¼ ë¡œë“œ ì¤‘... ({FILE_NAME})\")\n",
    "    try:\n",
    "        df = pd.read_csv(FILE_NAME, encoding='utf-8')\n",
    "    except UnicodeDecodeError:\n",
    "        df = pd.read_csv(FILE_NAME, encoding='cp949')\n",
    "\n",
    "    # (1) ì»¬ëŸ¼ëª… ë§¤í•‘\n",
    "    rename_map = {\n",
    "        'ê³ ìœ ì—­ë²ˆí˜¸(ì™¸ë¶€ì—­ì½”ë“œ)': 'stnCd',\n",
    "        'ì—­ëª…': 'stnNm',\n",
    "        'ìœ„ë„': 'lat',\n",
    "        'ê²½ë„': 'lon'\n",
    "    }\n",
    "    df.rename(columns=rename_map, inplace=True)\n",
    "\n",
    "    # (2) í˜¸ì„ ëª… ë³€í™˜ (1 -> 1í˜¸ì„ )\n",
    "    # í˜¸ì„  ëª…ì¹­ì€ '1í˜¸ì„ 'ìœ¼ë¡œ ìœ ì§€í•´ì•¼ ì¡°ì¸ì´ ë˜ë¯€ë¡œ ì´ ë¡œì§ì€ ë‚¨ê²¨ë‘¡ë‹ˆë‹¤.\n",
    "    if 'í˜¸ì„ ' in df.columns:\n",
    "        df['lineNm'] = df['í˜¸ì„ '].astype(str).apply(lambda x: x + 'í˜¸ì„ ' if x.isdigit() else x)\n",
    "    else:\n",
    "        df['lineNm'] = 'ì •ë³´ì—†ìŒ'\n",
    "\n",
    "    # ---------------------------------------------------------\n",
    "    # ğŸ”„ [ì›ìƒ ë³µêµ¬] ì—­ì½”ë“œ 0 ì±„ìš°ê¸°(zfill) ì œê±°\n",
    "    # ---------------------------------------------------------\n",
    "    # CSVì— ìˆëŠ” ê·¸ëŒ€ë¡œ '150' í˜•íƒœë¡œ ë³€í™˜í•©ë‹ˆë‹¤.\n",
    "    df['stnCd'] = df['stnCd'].astype(str).str.strip()\n",
    "    \n",
    "    # ê³µë°± ì œê±° ë° ìˆ«ì ë³€í™˜\n",
    "    df['stnNm'] = df['stnNm'].astype(str).str.strip()\n",
    "    df['lat'] = pd.to_numeric(df['lat'], errors='coerce')\n",
    "    df['lon'] = pd.to_numeric(df['lon'], errors='coerce')\n",
    "\n",
    "    # ê²°ì¸¡ì¹˜ ì œê±°\n",
    "    df_clean = df.dropna(subset=['lat', 'lon', 'stnCd'])\n",
    "    \n",
    "    target_cols = ['stnCd', 'stnNm', 'lineNm', 'lat', 'lon']\n",
    "    return df_clean[target_cols]\n",
    "\n",
    "# ---------------------------------------------------------\n",
    "# 2. DB ì´ˆê¸°í™” ë° ì¬ì ì¬ í•¨ìˆ˜\n",
    "# ---------------------------------------------------------\n",
    "def reset_and_insert(conn, df):\n",
    "    if df.empty:\n",
    "        return\n",
    "\n",
    "    cursor = conn.cursor()\n",
    "    \n",
    "    try:\n",
    "        # 1. í…Œì´ë¸” ì´ˆê¸°í™” (ê¸°ì¡´ ë°ì´í„° ì‚­ì œ)\n",
    "        print(\"ğŸ§¹ ê¸°ì¡´ station_meta í…Œì´ë¸”ì„ ë¹„ìš°ëŠ” ì¤‘ (TRUNCATE)...\")\n",
    "        cursor.execute(\"TRUNCATE TABLE station_meta\")\n",
    "        conn.commit()\n",
    "        \n",
    "        # 2. ë°ì´í„° ì ì¬\n",
    "        print(\"ğŸ“¥ ì›ë³¸ ë°ì´í„° ì ì¬ ì‹œì‘...\")\n",
    "        sql = \"\"\"\n",
    "            INSERT INTO station_meta (stnCd, stnNm, lineNm, lat, lon)\n",
    "            VALUES (%s, %s, %s, %s, %s)\n",
    "        \"\"\"\n",
    "        data_tuples = [tuple(x) for x in df.to_numpy()]\n",
    "        cursor.executemany(sql, data_tuples)\n",
    "        conn.commit()\n",
    "        \n",
    "        print(f\"âœ… ì›ìƒ ë³µêµ¬ ì™„ë£Œ! (ì´ {len(data_tuples)}ê±´)\")\n",
    "        \n",
    "        # ê²€ì¦\n",
    "        print(\"\\nğŸ” [ê²€ì¦] ì„œìš¸ì—­ ì½”ë“œê°€ '150'ìœ¼ë¡œ ëŒì•„ì™”ëŠ”ì§€ í™•ì¸:\")\n",
    "        cursor.execute(\"SELECT * FROM station_meta WHERE stnNm = 'ì„œìš¸ì—­' LIMIT 1\")\n",
    "        print(cursor.fetchone())\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"âŒ ì‘ì—… ì‹¤íŒ¨: {e}\")\n",
    "        conn.rollback()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # ë°ì´í„° ì¤€ë¹„\n",
    "    df_result = load_original_csv()\n",
    "    \n",
    "    # DB ì—°ê²° ë° ì‹¤í–‰\n",
    "    conn = dbconnect.MydbConnect('seoul_urban_lab')\n",
    "    reset_and_insert(conn, df_result)\n",
    "    conn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a9f86c72",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ•µï¸â€â™‚ï¸ [ì§„ë‹¨ ì‹œì‘] 1~4í˜¸ì„  ë°ì´í„° ë§¤ì¹­ ì‹¤íŒ¨ ì›ì¸ ë¶„ì„\n",
      "\n",
      "ë°ì´í„°ë² ì´ì„œ ì—°ê²° ì‹œì‘!\n",
      "MySQL DB ì—°ê²° ì„±ê³µ\n",
      "1ï¸âƒ£ [subway_traffic_log] ìŠ¹ê° ë°ì´í„°ì˜ 1í˜¸ì„  ì—­ ì½”ë“œ ìƒ˜í”Œ:\n",
      "lineNm stnCd        stnNm\n",
      "   1í˜¸ì„   0159          ë™ë¬˜ì•\n",
      "   1í˜¸ì„   0158 ì²­ëŸ‰ë¦¬(ì„œìš¸ì‹œë¦½ëŒ€ì…êµ¬)\n",
      "   1í˜¸ì„   0157          ì œê¸°ë™\n",
      "   1í˜¸ì„   0156          ì‹ ì„¤ë™\n",
      "   1í˜¸ì„   0155          ë™ëŒ€ë¬¸\n",
      "   ğŸ‘‰ ì‹¤ì œ ì €ì¥ëœ ê°’: '0159' (ê¸¸ì´: 4)\n",
      "--------------------------------------------------\n",
      "2ï¸âƒ£ [station_meta] ì¢Œí‘œ ë°ì´í„°ì˜ 1í˜¸ì„  ì—­ ì½”ë“œ ìƒ˜í”Œ:\n",
      "lineNm stnCd stnNm\n",
      "   1í˜¸ì„    150    ì„œìš¸\n",
      "   1í˜¸ì„    151    ì‹œì²­\n",
      "   1í˜¸ì„    152    ì¢…ê°\n",
      "   1í˜¸ì„    153  ì¢…ë¡œ3ê°€\n",
      "   1í˜¸ì„    154  ì¢…ë¡œ5ê°€\n",
      "   ğŸ‘‰ ì‹¤ì œ ì €ì¥ëœ ê°’: '150' (ê¸¸ì´: 3)\n",
      "--------------------------------------------------\n",
      "3ï¸âƒ£ [ê²°ë¡ ] ë‘ í…Œì´ë¸” ì¡°ì¸ ì‹œë„ ê²°ê³¼:\n",
      "   âŒ ë§¤ì¹­ëœ ë°ì´í„° ê±´ìˆ˜: 0ê±´\n",
      "   ğŸ’¡ ì›ì¸: í•œìª½ì€ '0150'(4ìë¦¬), ë‹¤ë¥¸ ìª½ì€ '150'(3ìë¦¬)ë¼ì„œ ì»´í“¨í„°ëŠ” ì„œë¡œ ë‹¤ë¥¸ ë¬¸ìë¡œ ì¸ì‹í•©ë‹ˆë‹¤.\n",
      "   ğŸ’¡ í•´ê²°ì±…: station_meta í…Œì´ë¸”ì˜ ì½”ë“œë¥¼ ë‹¤ì‹œ 4ìë¦¬('0150')ë¡œ ë§ì¶°ì¤˜ì•¼ í•©ë‹ˆë‹¤.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_4116\\2594537732.py:22: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  df_log = pd.read_sql(sql_log, conn)\n",
      "C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_4116\\2594537732.py:43: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  df_meta = pd.read_sql(sql_meta, conn)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import dbconnect\n",
    "import sys\n",
    "\n",
    "def diagnose_join_issue():\n",
    "    print(\"ğŸ•µï¸â€â™‚ï¸ [ì§„ë‹¨ ì‹œì‘] 1~4í˜¸ì„  ë°ì´í„° ë§¤ì¹­ ì‹¤íŒ¨ ì›ì¸ ë¶„ì„\\n\")\n",
    "    \n",
    "    conn = dbconnect.MydbConnect('seoul_urban_lab')\n",
    "    cursor = conn.cursor()\n",
    "\n",
    "    try:\n",
    "        # ---------------------------------------------------------\n",
    "        # 1. API ìŠ¹í•˜ì°¨ í…Œì´ë¸”(subway_traffic_log)ì˜ 1í˜¸ì„  ì½”ë“œ í™•ì¸\n",
    "        # ---------------------------------------------------------\n",
    "        print(\"1ï¸âƒ£ [subway_traffic_log] ìŠ¹ê° ë°ì´í„°ì˜ 1í˜¸ì„  ì—­ ì½”ë“œ ìƒ˜í”Œ:\")\n",
    "        sql_log = \"\"\"\n",
    "            SELECT DISTINCT lineNm, stnCd, stnNm \n",
    "            FROM subway_traffic_log \n",
    "            WHERE lineNm = '1í˜¸ì„ ' \n",
    "            LIMIT 5\n",
    "        \"\"\"\n",
    "        df_log = pd.read_sql(sql_log, conn)\n",
    "        if df_log.empty:\n",
    "            print(\"   âš ï¸ ìŠ¹ê° ë°ì´í„°ì— 1í˜¸ì„  ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.\")\n",
    "        else:\n",
    "            print(df_log.to_string(index=False))\n",
    "            # ë°ì´í„° íƒ€ì… í™•ì¸ì„ ìœ„í•´ ë”°ì˜´í‘œë¡œ ê°ì‹¸ì„œ ì¶œë ¥\n",
    "            sample_code = df_log.iloc[0]['stnCd']\n",
    "            print(f\"   ğŸ‘‰ ì‹¤ì œ ì €ì¥ëœ ê°’: '{sample_code}' (ê¸¸ì´: {len(sample_code)})\")\n",
    "\n",
    "        print(\"-\" * 50)\n",
    "\n",
    "        # ---------------------------------------------------------\n",
    "        # 2. ì¢Œí‘œ ë§ˆìŠ¤í„° í…Œì´ë¸”(station_meta)ì˜ 1í˜¸ì„  ì½”ë“œ í™•ì¸\n",
    "        # ---------------------------------------------------------\n",
    "        print(\"2ï¸âƒ£ [station_meta] ì¢Œí‘œ ë°ì´í„°ì˜ 1í˜¸ì„  ì—­ ì½”ë“œ ìƒ˜í”Œ:\")\n",
    "        sql_meta = \"\"\"\n",
    "            SELECT DISTINCT lineNm, stnCd, stnNm \n",
    "            FROM station_meta \n",
    "            WHERE lineNm = '1í˜¸ì„ ' \n",
    "            LIMIT 5\n",
    "        \"\"\"\n",
    "        df_meta = pd.read_sql(sql_meta, conn)\n",
    "        if df_meta.empty:\n",
    "            print(\"   âš ï¸ ì¢Œí‘œ ë°ì´í„°ì— 1í˜¸ì„  ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.\")\n",
    "        else:\n",
    "            print(df_meta.to_string(index=False))\n",
    "            sample_code = df_meta.iloc[0]['stnCd']\n",
    "            print(f\"   ğŸ‘‰ ì‹¤ì œ ì €ì¥ëœ ê°’: '{sample_code}' (ê¸¸ì´: {len(sample_code)})\")\n",
    "\n",
    "        print(\"-\" * 50)\n",
    "\n",
    "        # ---------------------------------------------------------\n",
    "        # 3. ì¡°ì¸(JOIN) í…ŒìŠ¤íŠ¸ ê²°ê³¼\n",
    "        # ---------------------------------------------------------\n",
    "        print(\"3ï¸âƒ£ [ê²°ë¡ ] ë‘ í…Œì´ë¸” ì¡°ì¸ ì‹œë„ ê²°ê³¼:\")\n",
    "        sql_join = \"\"\"\n",
    "            SELECT COUNT(*) \n",
    "            FROM subway_traffic_log t\n",
    "            JOIN station_meta m ON t.stnCd = m.stnCd\n",
    "            WHERE t.lineNm = '1í˜¸ì„ '\n",
    "        \"\"\"\n",
    "        cursor.execute(sql_join)\n",
    "        count = cursor.fetchone()[0]\n",
    "        \n",
    "        if count == 0:\n",
    "            print(f\"   âŒ ë§¤ì¹­ëœ ë°ì´í„° ê±´ìˆ˜: {count}ê±´\")\n",
    "            print(\"   ğŸ’¡ ì›ì¸: í•œìª½ì€ '0150'(4ìë¦¬), ë‹¤ë¥¸ ìª½ì€ '150'(3ìë¦¬)ë¼ì„œ ì»´í“¨í„°ëŠ” ì„œë¡œ ë‹¤ë¥¸ ë¬¸ìë¡œ ì¸ì‹í•©ë‹ˆë‹¤.\")\n",
    "            print(\"   ğŸ’¡ í•´ê²°ì±…: station_meta í…Œì´ë¸”ì˜ ì½”ë“œë¥¼ ë‹¤ì‹œ 4ìë¦¬('0150')ë¡œ ë§ì¶°ì¤˜ì•¼ í•©ë‹ˆë‹¤.\")\n",
    "        else:\n",
    "            print(f\"   âœ… ë§¤ì¹­ëœ ë°ì´í„° ê±´ìˆ˜: {count}ê±´ (ì •ìƒ)\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"âŒ ì§„ë‹¨ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}\")\n",
    "        \n",
    "    finally:\n",
    "        conn.close()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    diagnose_join_issue()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "74071e93",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ› ï¸ [ë°ì´í„° ë™ê¸°í™”] subway_traffic_logì˜ ì—­ ì½”ë“œë¥¼ ìˆ˜ì •í•©ë‹ˆë‹¤ (0150 -> 150)...\n",
      "ë°ì´í„°ë² ì´ì„œ ì—°ê²° ì‹œì‘!\n",
      "MySQL DB ì—°ê²° ì„±ê³µ\n",
      "1ï¸âƒ£ ë³€ê²½ ì „ ìƒíƒœ í™•ì¸ (1í˜¸ì„  ìƒ˜í”Œ):\n",
      "   - ('0159', 'ë™ë¬˜ì•')\n",
      "   - ('0158', 'ì²­ëŸ‰ë¦¬(ì„œìš¸ì‹œë¦½ëŒ€ì…êµ¬)')\n",
      "   - ('0157', 'ì œê¸°ë™')\n",
      "\n",
      "2ï¸âƒ£ UPDATE ì¿¼ë¦¬ ì‹¤í–‰ ì¤‘...\n",
      "   âœ… ì—…ë°ì´íŠ¸ ì™„ë£Œ! ì´ 124709ê±´ì˜ ë°ì´í„°ê°€ ìˆ˜ì •ë˜ì—ˆìŠµë‹ˆë‹¤.\n",
      "\n",
      "3ï¸âƒ£ ë³€ê²½ í›„ ì¡°ì¸ í…ŒìŠ¤íŠ¸ (subway_traffic_log â†” station_meta):\n",
      "   ğŸ‰ ë§¤ì¹­ ì„±ê³µ! \n",
      "   ('ì„œìš¸ì—­', '1í˜¸ì„ ', '150', '150', Decimal('37.5531500'), Decimal('126.9725330'))\n",
      "   ì´ì œ Streamlit ì§€ë„ì—ì„œ 1í˜¸ì„ ì´ ì •ìƒì ìœ¼ë¡œ ë³´ì¼ ê²ƒì…ë‹ˆë‹¤.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import dbconnect\n",
    "import sys\n",
    "\n",
    "def fix_station_codes():\n",
    "    print(\"ğŸ› ï¸ [ë°ì´í„° ë™ê¸°í™”] subway_traffic_logì˜ ì—­ ì½”ë“œë¥¼ ìˆ˜ì •í•©ë‹ˆë‹¤ (0150 -> 150)...\")\n",
    "    \n",
    "    conn = dbconnect.MydbConnect('seoul_urban_lab')\n",
    "    cursor = conn.cursor()\n",
    "\n",
    "    try:\n",
    "        # ---------------------------------------------------------\n",
    "        # 1. ìˆ˜ì • ëŒ€ìƒ ë°ì´í„° í™•ì¸ (ì—…ë°ì´íŠ¸ ì „)\n",
    "        # ---------------------------------------------------------\n",
    "        print(\"1ï¸âƒ£ ë³€ê²½ ì „ ìƒíƒœ í™•ì¸ (1í˜¸ì„  ìƒ˜í”Œ):\")\n",
    "        check_sql = \"SELECT DISTINCT stnCd, stnNm FROM subway_traffic_log WHERE stnCd LIKE '015%' LIMIT 3\"\n",
    "        cursor.execute(check_sql)\n",
    "        before_rows = cursor.fetchall()\n",
    "        for row in before_rows:\n",
    "            print(f\"   - {row}\")\n",
    "\n",
    "        if not before_rows:\n",
    "            print(\"   (ì´ë¯¸ '0'ì´ ì œê±°ë˜ì—ˆê±°ë‚˜ ëŒ€ìƒ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.)\")\n",
    "\n",
    "        # ---------------------------------------------------------\n",
    "        # 2. UPDATE ì¿¼ë¦¬ ì‹¤í–‰ (í•µì‹¬)\n",
    "        # ---------------------------------------------------------\n",
    "        # LEADING '0' FROM stnCd : ì•ì— ìˆëŠ” 0ë§Œ ì œê±° (ì¤‘ê°„ì˜ 0ì€ ìœ ì§€)\n",
    "        print(\"\\n2ï¸âƒ£ UPDATE ì¿¼ë¦¬ ì‹¤í–‰ ì¤‘...\")\n",
    "        \n",
    "        update_sql = \"\"\"\n",
    "            UPDATE subway_traffic_log \n",
    "            SET stnCd = TRIM(LEADING '0' FROM stnCd)\n",
    "            WHERE stnCd LIKE '0%';\n",
    "        \"\"\"\n",
    "        cursor.execute(update_sql)\n",
    "        affected_rows = cursor.rowcount\n",
    "        conn.commit()\n",
    "        \n",
    "        print(f\"   âœ… ì—…ë°ì´íŠ¸ ì™„ë£Œ! ì´ {affected_rows}ê±´ì˜ ë°ì´í„°ê°€ ìˆ˜ì •ë˜ì—ˆìŠµë‹ˆë‹¤.\")\n",
    "\n",
    "        # ---------------------------------------------------------\n",
    "        # 3. ë³€ê²½ í›„ ì¡°ì¸(Join) í…ŒìŠ¤íŠ¸\n",
    "        # ---------------------------------------------------------\n",
    "        print(\"\\n3ï¸âƒ£ ë³€ê²½ í›„ ì¡°ì¸ í…ŒìŠ¤íŠ¸ (subway_traffic_log â†” station_meta):\")\n",
    "        \n",
    "        # 1í˜¸ì„  ì„œìš¸ì—­(150) ê¸°ì¤€ìœ¼ë¡œ ì˜ ë¶™ëŠ”ì§€ í™•ì¸\n",
    "        test_join_sql = \"\"\"\n",
    "            SELECT t.stnNm, t.lineNm, t.stnCd as Traffic_Code, m.stnCd as Meta_Code, m.lat, m.lon\n",
    "            FROM subway_traffic_log t\n",
    "            JOIN station_meta m ON t.stnCd = m.stnCd\n",
    "            WHERE t.stnNm = 'ì„œìš¸ì—­' AND t.lineNm = '1í˜¸ì„ '\n",
    "            LIMIT 1\n",
    "        \"\"\"\n",
    "        \n",
    "        cursor.execute(test_join_sql)\n",
    "        result = cursor.fetchone()\n",
    "        \n",
    "        if result:\n",
    "            print(f\"   ğŸ‰ ë§¤ì¹­ ì„±ê³µ! \\n   {result}\")\n",
    "            print(\"   ì´ì œ Streamlit ì§€ë„ì—ì„œ 1í˜¸ì„ ì´ ì •ìƒì ìœ¼ë¡œ ë³´ì¼ ê²ƒì…ë‹ˆë‹¤.\")\n",
    "        else:\n",
    "            print(\"   âŒ ì—¬ì „íˆ ë§¤ì¹­ë˜ì§€ ì•ŠìŠµë‹ˆë‹¤. ì½”ë“œë¥¼ ë‹¤ì‹œ í™•ì¸í•´ì•¼ í•©ë‹ˆë‹¤.\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"âŒ ì‘ì—… ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}\")\n",
    "        conn.rollback()\n",
    "        \n",
    "    finally:\n",
    "        conn.close()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    fix_station_codes()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ee8ad5a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“‚ ë°±ì—… í´ë” ìƒì„± ì™„ë£Œ: backup_csv/\n",
      "ğŸ”Œ DB ì—°ê²° ì‹œë„...\n",
      "ë°ì´í„°ë² ì´ì„œ ì—°ê²° ì‹œì‘!\n",
      "MySQL DB ì—°ê²° ì„±ê³µ\n",
      "\n",
      "ğŸ”„ [Export] 'subway_traffic_log' ë‚´ë³´ë‚´ëŠ” ì¤‘...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_4116\\4003510457.py:42: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  df = pd.read_sql(sql, conn)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   âœ… ì €ì¥ ì™„ë£Œ! (262044í–‰)\n",
      "      -> ê²½ë¡œ: backup_csv\\subway_traffic_log_latest.csv\n",
      "\n",
      "ğŸ”„ [Export] 'subway_traffic_log_senior_22-24' ë‚´ë³´ë‚´ëŠ” ì¤‘...\n",
      "   âœ… ì €ì¥ ì™„ë£Œ! (5965194í–‰)\n",
      "      -> ê²½ë¡œ: backup_csv\\subway_traffic_senior_22_24.csv\n",
      "\n",
      "==================================================\n",
      "ğŸ‰ ëª¨ë“  ë‚´ë³´ë‚´ê¸° ì‘ì—…ì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤.\n",
      "==================================================\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import sys\n",
    "import dbconnect  # dbconnect.py ëª¨ë“ˆ í™œìš©\n",
    "\n",
    "# ---------------------------------------------------------\n",
    "# 1. ì„¤ì •: ë‚´ë³´ë‚¼ í…Œì´ë¸” ë¦¬ìŠ¤íŠ¸ì™€ ì €ì¥ ê²½ë¡œ\n",
    "# ---------------------------------------------------------\n",
    "OUTPUT_DIR = \"backup_csv\"  # ì €ì¥í•  í´ë”ëª…\n",
    "\n",
    "# (í…Œì´ë¸”ëª…, ì €ì¥í•  íŒŒì¼ëª…) íŠœí”Œ ë¦¬ìŠ¤íŠ¸\n",
    "TARGET_TABLES = [\n",
    "    (\"subway_traffic_log\", \"subway_traffic_log_latest.csv\"),\n",
    "    (\"subway_traffic_log_senior_22-24\", \"subway_traffic_senior_22_24.csv\")\n",
    "]\n",
    "\n",
    "def export_data():\n",
    "    # ì €ì¥ í´ë” ìƒì„± (ì—†ìœ¼ë©´ ìƒì„±)\n",
    "    if not os.path.exists(OUTPUT_DIR):\n",
    "        os.makedirs(OUTPUT_DIR)\n",
    "        print(f\"ğŸ“‚ ë°±ì—… í´ë” ìƒì„± ì™„ë£Œ: {OUTPUT_DIR}/\")\n",
    "\n",
    "    print(\"ğŸ”Œ DB ì—°ê²° ì‹œë„...\")\n",
    "    conn = dbconnect.MydbConnect('seoul_urban_lab')\n",
    "\n",
    "    try:\n",
    "        for table_name, file_name in TARGET_TABLES:\n",
    "            print(f\"\\nğŸ”„ [Export] '{table_name}' ë‚´ë³´ë‚´ëŠ” ì¤‘...\")\n",
    "            \n",
    "            # -----------------------------------------------------\n",
    "            # SQL ì¿¼ë¦¬ ì‘ì„± (íŠ¹ìˆ˜ë¬¸ì í¬í•¨ í…Œì´ë¸”ëª… ì²˜ë¦¬)\n",
    "            # -----------------------------------------------------\n",
    "            # í…Œì´ë¸”ëª…ì— í•˜ì´í”ˆ(-)ì´ ìˆìœ¼ë¯€ë¡œ ë°˜ë“œì‹œ ë°±í‹±(`)ìœ¼ë¡œ ê°ì‹¸ì•¼ í•©ë‹ˆë‹¤.\n",
    "            sql = f\"SELECT * FROM `{table_name}`\"\n",
    "            \n",
    "            # -----------------------------------------------------\n",
    "            # ë°ì´í„° ì¡°íšŒ (pandas read_sql í™œìš©)\n",
    "            # -----------------------------------------------------\n",
    "            try:\n",
    "                # chunksizeë¥¼ ì„¤ì •í•˜ë©´ ë©”ëª¨ë¦¬ ë¶€ì¡±ì„ ë°©ì§€í•  ìˆ˜ ìˆìœ¼ë‚˜, \n",
    "                # í˜„ì¬ ê·œëª¨ì—ì„œëŠ” í•œ ë²ˆì— ë¶ˆëŸ¬ì™€ë„ ë¬´ë°©í•©ë‹ˆë‹¤.\n",
    "                df = pd.read_sql(sql, conn)\n",
    "                \n",
    "                if df.empty:\n",
    "                    print(f\"   âš ï¸ ê²½ê³ : í…Œì´ë¸”ì´ ë¹„ì–´ìˆìŠµë‹ˆë‹¤.\")\n",
    "                    continue\n",
    "                \n",
    "                # -----------------------------------------------------\n",
    "                # CSV ì €ì¥\n",
    "                # -----------------------------------------------------\n",
    "                # encoding='utf-8-sig': ì—‘ì…€ì—ì„œ í•œê¸€ì´ ê¹¨ì§€ì§€ ì•Šê²Œ í•¨\n",
    "                save_path = os.path.join(OUTPUT_DIR, file_name)\n",
    "                df.to_csv(save_path, index=False, encoding='utf-8-sig')\n",
    "                \n",
    "                print(f\"   âœ… ì €ì¥ ì™„ë£Œ! ({len(df)}í–‰)\")\n",
    "                print(f\"      -> ê²½ë¡œ: {save_path}\")\n",
    "                \n",
    "            except Exception as e:\n",
    "                print(f\"   âŒ í…Œì´ë¸” ì¡°íšŒ ì‹¤íŒ¨: {e}\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"âŒ ì‘ì—… ì¤‘ ì¹˜ëª…ì  ì˜¤ë¥˜: {e}\")\n",
    "        \n",
    "    finally:\n",
    "        conn.close()\n",
    "        print(\"\\n\" + \"=\"*50)\n",
    "        print(\"ğŸ‰ ëª¨ë“  ë‚´ë³´ë‚´ê¸° ì‘ì—…ì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤.\")\n",
    "        print(\"=\"*50)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    export_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c558ce35",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ•µï¸â€â™‚ï¸ [ì¶”ì  ì‹œì‘] ì§€ë„ì—ì„œ ì‚¬ë¼ì§„ 4ê°œ ì—­ì„ ì°¾ìŠµë‹ˆë‹¤...\n",
      "\n",
      "ë°ì´í„°ë² ì´ì„œ ì—°ê²° ì‹œì‘!\n",
      "MySQL DB ì—°ê²° ì„±ê³µ\n",
      "âœ… ê¸°ì¤€(Meta) ì—­ ê°œìˆ˜: 276ê°œ\n",
      "\n",
      "ğŸ” [1ë‹¨ê³„] API ìŠ¹ê° ë°ì´í„°(subway_traffic_log)ì™€ ë¹„êµ\n",
      "   âš ï¸ ì´ 1ê°œ ì—­ì´ ìŠ¹ê° ë°ì´í„°ì— ì—†ìŠµë‹ˆë‹¤.\n",
      "   ğŸ‘‰ ì•„ë˜ ì—­ë“¤ì€ íŠ¸ë˜í”½ ë°ì´í„°ê°€ ì—†ì–´ì„œ ì§€ë„ì— ì•ˆ ë‚˜ì˜µë‹ˆë‹¤:\n",
      "stnCd stnNm lineNm\n",
      "  200   ê¹Œì¹˜ì‚°    2í˜¸ì„ \n",
      "\n",
      "ğŸ” [2ë‹¨ê³„] ë…¸ì¸ ë°ì´í„°(subway_traffic_log_senior_22-24)ì™€ ë¹„êµ\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_4116\\3871461358.py:15: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  df_meta = pd.read_sql(sql_meta, conn)\n",
      "C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_4116\\3871461358.py:25: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  df_log = pd.read_sql(sql_log, conn)\n",
      "C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_4116\\3871461358.py:47: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  df_senior = pd.read_sql(sql_senior, conn)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   âš ï¸ ì´ 1ê°œ ì—­ì´ ë…¸ì¸ ë°ì´í„°ì— ì—†ìŠµë‹ˆë‹¤.\n",
      "stnCd stnNm lineNm\n",
      "  200   ê¹Œì¹˜ì‚°    2í˜¸ì„ \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import dbconnect\n",
    "import sys\n",
    "\n",
    "def find_ghost_stations():\n",
    "    print(\"ğŸ•µï¸â€â™‚ï¸ [ì¶”ì  ì‹œì‘] ì§€ë„ì—ì„œ ì‚¬ë¼ì§„ 4ê°œ ì—­ì„ ì°¾ìŠµë‹ˆë‹¤...\\n\")\n",
    "    \n",
    "    conn = dbconnect.MydbConnect('seoul_urban_lab')\n",
    "    \n",
    "    try:\n",
    "        # ---------------------------------------------------------\n",
    "        # 1. ê¸°ì¤€ ë°ì´í„° (Meta) ê°€ì ¸ì˜¤ê¸° - 276ê°œ\n",
    "        # ---------------------------------------------------------\n",
    "        sql_meta = \"SELECT stnCd, stnNm, lineNm FROM station_meta\"\n",
    "        df_meta = pd.read_sql(sql_meta, conn)\n",
    "        meta_set = set(df_meta['stnCd'])\n",
    "        \n",
    "        print(f\"âœ… ê¸°ì¤€(Meta) ì—­ ê°œìˆ˜: {len(df_meta)}ê°œ\")\n",
    "\n",
    "        # ---------------------------------------------------------\n",
    "        # 2. ìµœê·¼ ìŠ¹ê° ë°ì´í„° (API ë¡œê·¸)ì™€ ë¹„êµ\n",
    "        # ---------------------------------------------------------\n",
    "        print(\"\\nğŸ” [1ë‹¨ê³„] API ìŠ¹ê° ë°ì´í„°(subway_traffic_log)ì™€ ë¹„êµ\")\n",
    "        sql_log = \"SELECT DISTINCT stnCd FROM subway_traffic_log\"\n",
    "        df_log = pd.read_sql(sql_log, conn)\n",
    "        log_set = set(df_log['stnCd'])\n",
    "        \n",
    "        # ì°¨ì§‘í•© ì—°ì‚° (Metaì—ëŠ” ìˆëŠ”ë° Logì—ëŠ” ì—†ëŠ” ê²ƒ)\n",
    "        missing_in_log = meta_set - log_set\n",
    "        \n",
    "        if missing_in_log:\n",
    "            print(f\"   âš ï¸ ì´ {len(missing_in_log)}ê°œ ì—­ì´ ìŠ¹ê° ë°ì´í„°ì— ì—†ìŠµë‹ˆë‹¤.\")\n",
    "            print(\"   ğŸ‘‰ ì•„ë˜ ì—­ë“¤ì€ íŠ¸ë˜í”½ ë°ì´í„°ê°€ ì—†ì–´ì„œ ì§€ë„ì— ì•ˆ ë‚˜ì˜µë‹ˆë‹¤:\")\n",
    "            \n",
    "            # ìƒì„¸ ì •ë³´ ì¶œë ¥\n",
    "            missing_df = df_meta[df_meta['stnCd'].isin(missing_in_log)]\n",
    "            print(missing_df.to_string(index=False))\n",
    "        else:\n",
    "            print(\"   âœ¨ ëª¨ë“  ì—­ì´ ì •ìƒì ìœ¼ë¡œ ë§¤ì¹­ë©ë‹ˆë‹¤.\")\n",
    "\n",
    "        # ---------------------------------------------------------\n",
    "        # 3. ë…¸ì¸ ë°ì´í„° (22-24ë…„)ì™€ ë¹„êµ\n",
    "        # ---------------------------------------------------------\n",
    "        print(\"\\nğŸ” [2ë‹¨ê³„] ë…¸ì¸ ë°ì´í„°(subway_traffic_log_senior_22-24)ì™€ ë¹„êµ\")\n",
    "        # í…Œì´ë¸”ëª…ì— ë°±í‹±(`) í•„ìˆ˜\n",
    "        sql_senior = \"SELECT DISTINCT stnCd FROM `subway_traffic_log_senior_22-24`\"\n",
    "        df_senior = pd.read_sql(sql_senior, conn)\n",
    "        senior_set = set(df_senior['stnCd'])\n",
    "        \n",
    "        missing_in_senior = meta_set - senior_set\n",
    "        \n",
    "        if missing_in_senior:\n",
    "            print(f\"   âš ï¸ ì´ {len(missing_in_senior)}ê°œ ì—­ì´ ë…¸ì¸ ë°ì´í„°ì— ì—†ìŠµë‹ˆë‹¤.\")\n",
    "            # ìƒì„¸ ì •ë³´ ì¶œë ¥ (ìƒìœ„ 10ê°œë§Œ)\n",
    "            missing_senior_df = df_meta[df_meta['stnCd'].isin(missing_in_senior)]\n",
    "            print(missing_senior_df.head(10).to_string(index=False))\n",
    "        else:\n",
    "            print(\"   âœ¨ ëª¨ë“  ì—­ì´ ì •ìƒì ìœ¼ë¡œ ë§¤ì¹­ë©ë‹ˆë‹¤.\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"âŒ ë¶„ì„ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}\")\n",
    "        \n",
    "    finally:\n",
    "        conn.close()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    find_ghost_stations()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ad8a5b30",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ•µï¸â€â™‚ï¸ [ì •ë°€ ì§„ë‹¨] ì§€ë„ì— í‘œì‹œë˜ëŠ” 'ìµœì‹  ë‚ ì§œ' ê¸°ì¤€ìœ¼ë¡œ ëˆ„ë½ëœ ì—­ì„ ì°¾ìŠµë‹ˆë‹¤...\n",
      "\n",
      "ë°ì´í„°ë² ì´ì„œ ì—°ê²° ì‹œì‘!\n",
      "MySQL DB ì—°ê²° ì„±ê³µ\n",
      "ğŸ“… ë¶„ì„ ê¸°ì¤€ ë‚ ì§œ (ìµœì‹ ): 20260201\n",
      "\n",
      "ğŸ“Š ë¶„ì„ ê²°ê³¼: ì´ 3ê°œ ì—­ì´ ëˆ„ë½ë˜ì—ˆìŠµë‹ˆë‹¤.\n",
      "ğŸ‘‡ [ëˆ„ë½ëœ ì—­ ëª…ë‹¨]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_4116\\129252472.py:18: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  df_meta = pd.read_sql(sql_meta, conn)\n",
      "C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_4116\\129252472.py:23: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  df_log = pd.read_sql(sql_log, conn)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>stnCd</th>\n",
       "      <th>stnNm</th>\n",
       "      <th>lineNm</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>200</td>\n",
       "      <td>ê¹Œì¹˜ì‚°</td>\n",
       "      <td>2í˜¸ì„ </td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>214</th>\n",
       "      <td>2615</td>\n",
       "      <td>ë´‰í™”ì‚°</td>\n",
       "      <td>6í˜¸ì„ </td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>215</th>\n",
       "      <td>2649</td>\n",
       "      <td>ì‹ ë‚´</td>\n",
       "      <td>6í˜¸ì„ </td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    stnCd stnNm lineNm\n",
       "60    200   ê¹Œì¹˜ì‚°    2í˜¸ì„ \n",
       "214  2615   ë´‰í™”ì‚°    6í˜¸ì„ \n",
       "215  2649    ì‹ ë‚´    6í˜¸ì„ "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ğŸ’¡ [ì›ì¸ ë¶„ì„]\n",
      "1. 'ê¹Œì¹˜ì‚°(2í˜¸ì„ )'ì€ ì• ì´ˆì— ë¡œê·¸ì— ì½”ë“œê°€ ì—†ì–´ì„œ ëˆ„ë½ë˜ì—ˆìŠµë‹ˆë‹¤.\n",
      "2. ë‚˜ë¨¸ì§€ ì—­ë“¤ì€ 'ì£¼ë§/ê³µíœ´ì¼'ì´ë¼ ìš´í–‰í•˜ì§€ ì•Šì•˜ê±°ë‚˜, í•´ë‹¹ ë‚ ì§œì—ë§Œ ì§‘ê³„ê°€ ì•ˆ ëœ ê²½ìš°ì…ë‹ˆë‹¤.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import dbconnect\n",
    "\n",
    "def check_missing_on_latest_date():\n",
    "    print(\"ğŸ•µï¸â€â™‚ï¸ [ì •ë°€ ì§„ë‹¨] ì§€ë„ì— í‘œì‹œë˜ëŠ” 'ìµœì‹  ë‚ ì§œ' ê¸°ì¤€ìœ¼ë¡œ ëˆ„ë½ëœ ì—­ì„ ì°¾ìŠµë‹ˆë‹¤...\\n\")\n",
    "    \n",
    "    conn = dbconnect.MydbConnect('seoul_urban_lab')\n",
    "    \n",
    "    try:\n",
    "        # 1. ìµœì‹  ë‚ ì§œ í™•ì¸\n",
    "        cursor = conn.cursor()\n",
    "        cursor.execute(\"SELECT MAX(pasngDe) FROM subway_traffic_log\")\n",
    "        latest_date = cursor.fetchone()[0]\n",
    "        print(f\"ğŸ“… ë¶„ì„ ê¸°ì¤€ ë‚ ì§œ (ìµœì‹ ): {latest_date}\")\n",
    "        \n",
    "        # 2. ê¸°ì¤€(Meta) ì—­ ì½”ë“œ ê°€ì ¸ì˜¤ê¸°\n",
    "        sql_meta = \"SELECT stnCd, stnNm, lineNm FROM station_meta\"\n",
    "        df_meta = pd.read_sql(sql_meta, conn)\n",
    "        meta_set = set(df_meta['stnCd'])\n",
    "        \n",
    "        # 3. ìµœì‹  ë‚ ì§œì˜ ìŠ¹ê° ë°ì´í„° ê°€ì ¸ì˜¤ê¸°\n",
    "        sql_log = f\"SELECT DISTINCT stnCd FROM subway_traffic_log WHERE pasngDe = '{latest_date}'\"\n",
    "        df_log = pd.read_sql(sql_log, conn)\n",
    "        log_set = set(df_log['stnCd'])\n",
    "        \n",
    "        # 4. ì°¨ì§‘í•© (Metaì—ëŠ” ìˆëŠ”ë°, ì˜¤ëŠ˜ì Logì—ëŠ” ì—†ëŠ” ê²ƒ)\n",
    "        missing_codes = meta_set - log_set\n",
    "        \n",
    "        print(f\"\\nğŸ“Š ë¶„ì„ ê²°ê³¼: ì´ {len(missing_codes)}ê°œ ì—­ì´ ëˆ„ë½ë˜ì—ˆìŠµë‹ˆë‹¤.\")\n",
    "        \n",
    "        if len(missing_codes) > 0:\n",
    "            print(\"ğŸ‘‡ [ëˆ„ë½ëœ ì—­ ëª…ë‹¨]\")\n",
    "            missing_df = df_meta[df_meta['stnCd'].isin(missing_codes)]\n",
    "            pd.set_option('display.max_rows', None)\n",
    "            display(missing_df)\n",
    "            \n",
    "            print(\"\\nğŸ’¡ [ì›ì¸ ë¶„ì„]\")\n",
    "            print(\"1. 'ê¹Œì¹˜ì‚°(2í˜¸ì„ )'ì€ ì• ì´ˆì— ë¡œê·¸ì— ì½”ë“œê°€ ì—†ì–´ì„œ ëˆ„ë½ë˜ì—ˆìŠµë‹ˆë‹¤.\")\n",
    "            print(\"2. ë‚˜ë¨¸ì§€ ì—­ë“¤ì€ 'ì£¼ë§/ê³µíœ´ì¼'ì´ë¼ ìš´í–‰í•˜ì§€ ì•Šì•˜ê±°ë‚˜, í•´ë‹¹ ë‚ ì§œì—ë§Œ ì§‘ê³„ê°€ ì•ˆ ëœ ê²½ìš°ì…ë‹ˆë‹¤.\")\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"âŒ ì˜¤ë¥˜ ë°œìƒ: {e}\")\n",
    "        \n",
    "    finally:\n",
    "        conn.close()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    check_missing_on_latest_date()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2130d8f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ•µï¸â€â™‚ï¸ [ì‹¬ì¸µ ë¶„ì„] ì‚¬ë¼ì§„ 3ê°œ ì—­ì˜ ì •ì²´ë¥¼ ë°í™ë‹ˆë‹¤...\n",
      "\n",
      "ë°ì´í„°ë² ì´ì„œ ì—°ê²° ì‹œì‘!\n",
      "MySQL DB ì—°ê²° ì„±ê³µ\n",
      "ğŸ“… ë¶„ì„ ë‚ ì§œ: 20260201\n",
      "ğŸ“Š ì˜¤ëŠ˜ ëˆ„ë½ëœ ì—­: ì´ 3ê°œ\n",
      "\n",
      " ì—­ì½”ë“œ  ì—­ëª…  í˜¸ì„                   ìƒíƒœ\n",
      " 200 ê¹Œì¹˜ì‚° 2í˜¸ì„  âŒ ì•„ì˜ˆ ë°ì´í„° ì—†ìŒ (ì˜êµ¬ ê²°ë²ˆ)\n",
      "2649  ì‹ ë‚´ 6í˜¸ì„     ğŸ’¤ ì˜¤ëŠ˜ì€ ì‰¼ (í‰ì¼ì—” ìˆìŒ)\n",
      "2615 ë´‰í™”ì‚° 6í˜¸ì„     ğŸ’¤ ì˜¤ëŠ˜ì€ ì‰¼ (í‰ì¼ì—” ìˆìŒ)\n",
      "\n",
      "==================================================\n",
      "ğŸ’¡ [ë¶„ì„ê°€ ì½”ë©˜íŠ¸]\n",
      "   - ì´ë¡ ìƒ ì§€ë„ì— ì°í˜€ì•¼ í•  ì—­ ê°œìˆ˜: 273ê°œ\n",
      "   - ë§Œì•½ Streamlitì—ì„œ 1ê°œê°€ ë” ì ê²Œ(272ê°œ) ë³´ì¸ë‹¤ë©´,\n",
      "     í˜¹ì‹œ 'ì—°ì‹ ë‚´(6í˜¸ì„ )'ì´ë‚˜ 'ì‹ ë‚´' ì²˜ëŸ¼ íŠ¹ì • ì—­ì˜ ì¢Œí‘œê°€ ê²¹ì³ìˆê±°ë‚˜,\n",
      "     ë°ì´í„°ë² ì´ìŠ¤ ì¡°íšŒ ì‹œì  ì°¨ì´ì¼ ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_26600\\2732310019.py:15: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  df_meta = pd.read_sql(\"SELECT stnCd, stnNm, lineNm FROM station_meta\", conn)\n",
      "C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_26600\\2732310019.py:18: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  df_log_today = pd.read_sql(f\"SELECT DISTINCT stnCd FROM subway_traffic_log WHERE pasngDe = '{latest_date}'\", conn)\n",
      "C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_26600\\2732310019.py:21: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  df_log_history = pd.read_sql(\"SELECT DISTINCT stnCd FROM subway_traffic_log\", conn)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import dbconnect\n",
    "\n",
    "def identify_missing_details():\n",
    "    print(\"ğŸ•µï¸â€â™‚ï¸ [ì‹¬ì¸µ ë¶„ì„] ì‚¬ë¼ì§„ 3ê°œ ì—­ì˜ ì •ì²´ë¥¼ ë°í™ë‹ˆë‹¤...\\n\")\n",
    "    conn = dbconnect.MydbConnect('seoul_urban_lab')\n",
    "    \n",
    "    try:\n",
    "        # 1. ìµœì‹  ë‚ ì§œ(ì–´ì œ) í™•ì¸\n",
    "        cursor = conn.cursor()\n",
    "        cursor.execute(\"SELECT MAX(pasngDe) FROM subway_traffic_log\")\n",
    "        latest_date = cursor.fetchone()[0]\n",
    "        \n",
    "        # 2. ë©”íƒ€ ë°ì´í„° (276ê°œ)\n",
    "        df_meta = pd.read_sql(\"SELECT stnCd, stnNm, lineNm FROM station_meta\", conn)\n",
    "        \n",
    "        # 3. ì–´ì œ ë¡œê·¸ ë°ì´í„°\n",
    "        df_log_today = pd.read_sql(f\"SELECT DISTINCT stnCd FROM subway_traffic_log WHERE pasngDe = '{latest_date}'\", conn)\n",
    "        \n",
    "        # 4. ì „ì²´ ì—­ì‚¬ ë¡œê·¸ ë°ì´í„° (ê³¼ê±° í¬í•¨)\n",
    "        df_log_history = pd.read_sql(\"SELECT DISTINCT stnCd FROM subway_traffic_log\", conn)\n",
    "        \n",
    "        # 5. [ë²”ì¸ ìƒ‰ì¶œ]\n",
    "        meta_set = set(df_meta['stnCd'])\n",
    "        today_set = set(df_log_today['stnCd'])\n",
    "        history_set = set(df_log_history['stnCd'])\n",
    "        \n",
    "        missing_today = meta_set - today_set # ì˜¤ëŠ˜ ì—†ëŠ” 3ê°œ\n",
    "        \n",
    "        print(f\"ğŸ“… ë¶„ì„ ë‚ ì§œ: {latest_date}\")\n",
    "        print(f\"ğŸ“Š ì˜¤ëŠ˜ ëˆ„ë½ëœ ì—­: ì´ {len(missing_today)}ê°œ\\n\")\n",
    "        \n",
    "        # ìƒì„¸ ë¶„ì„ ë£¨í”„\n",
    "        results = []\n",
    "        for code in missing_today:\n",
    "            info = df_meta[df_meta['stnCd'] == code].iloc[0]\n",
    "            \n",
    "            # ê³¼ê±°ì—ëŠ” ìˆì—ˆë‚˜?\n",
    "            is_in_history = code in history_set\n",
    "            \n",
    "            status = \"\"\n",
    "            if not is_in_history:\n",
    "                status = \"âŒ ì•„ì˜ˆ ë°ì´í„° ì—†ìŒ (ì˜êµ¬ ê²°ë²ˆ)\"\n",
    "            else:\n",
    "                status = \"ğŸ’¤ ì˜¤ëŠ˜ì€ ì‰¼ (í‰ì¼ì—” ìˆìŒ)\"\n",
    "                \n",
    "            results.append({\n",
    "                'ì—­ì½”ë“œ': code,\n",
    "                'ì—­ëª…': info['stnNm'],\n",
    "                'í˜¸ì„ ': info['lineNm'],\n",
    "                'ìƒíƒœ': status\n",
    "            })\n",
    "            \n",
    "        # ê²°ê³¼ ì¶œë ¥\n",
    "        df_result = pd.DataFrame(results)\n",
    "        print(df_result.to_string(index=False))\n",
    "        \n",
    "        print(\"\\n\" + \"=\"*50)\n",
    "        print(\"ğŸ’¡ [ë¶„ì„ê°€ ì½”ë©˜íŠ¸]\")\n",
    "        \n",
    "        # 272ê°œ vs 273ê°œ ë¯¸ìŠ¤í„°ë¦¬ í•´ê²°\n",
    "        expected_cnt = 276 - len(missing_today)\n",
    "        print(f\"   - ì´ë¡ ìƒ ì§€ë„ì— ì°í˜€ì•¼ í•  ì—­ ê°œìˆ˜: {expected_cnt}ê°œ\")\n",
    "        print(\"   - ë§Œì•½ Streamlitì—ì„œ 1ê°œê°€ ë” ì ê²Œ(272ê°œ) ë³´ì¸ë‹¤ë©´,\")\n",
    "        print(\"     í˜¹ì‹œ 'ì—°ì‹ ë‚´(6í˜¸ì„ )'ì´ë‚˜ 'ì‹ ë‚´' ì²˜ëŸ¼ íŠ¹ì • ì—­ì˜ ì¢Œí‘œê°€ ê²¹ì³ìˆê±°ë‚˜,\")\n",
    "        print(\"     ë°ì´í„°ë² ì´ìŠ¤ ì¡°íšŒ ì‹œì  ì°¨ì´ì¼ ìˆ˜ ìˆìŠµë‹ˆë‹¤.\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"âŒ ì˜¤ë¥˜: {e}\")\n",
    "        \n",
    "    finally:\n",
    "        conn.close()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    identify_missing_details()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "312900bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“¤ [Export] station_meta í…Œì´ë¸”ì„ CSVë¡œ ë‚´ë³´ëƒ…ë‹ˆë‹¤...\n",
      "ë°ì´í„°ë² ì´ì„œ ì—°ê²° ì‹œì‘!\n",
      "MySQL DB ì—°ê²° ì„±ê³µ\n",
      "\n",
      "âœ… ë‚´ë³´ë‚´ê¸° ì™„ë£Œ!\n",
      "   - íŒŒì¼ëª…: station_meta_backup.csv\n",
      "   - ì €ì¥ ê²½ë¡œ: c:\\Users\\Admin\\Desktop\\hdc2\\0202 í”„ë¡œì íŠ¸ êµ¬ì¶•\\station_meta_backup.csv\n",
      "   - ì´ ë°ì´í„°: 276ê±´\n",
      "\n",
      "[ë°ì´í„° ë¯¸ë¦¬ë³´ê¸°]\n",
      "   id stnCd stnNm lineNm        lat         lon          created_at\n",
      "0   1   150    ì„œìš¸    1í˜¸ì„   37.553150  126.972533 2026-02-02 14:43:16\n",
      "1   2   151    ì‹œì²­    1í˜¸ì„   37.563590  126.975407 2026-02-02 14:43:16\n",
      "2   3   152    ì¢…ê°    1í˜¸ì„   37.570203  126.983116 2026-02-02 14:43:16\n",
      "3   4   153  ì¢…ë¡œ3ê°€    1í˜¸ì„   37.570429  126.992095 2026-02-02 14:43:16\n",
      "4   5   154  ì¢…ë¡œ5ê°€    1í˜¸ì„   37.570971  127.001900 2026-02-02 14:43:16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_26600\\3519676216.py:16: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  df = pd.read_sql(sql, conn)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import dbconnect\n",
    "import os\n",
    "\n",
    "def export_station_meta():\n",
    "    print(\"ğŸ“¤ [Export] station_meta í…Œì´ë¸”ì„ CSVë¡œ ë‚´ë³´ëƒ…ë‹ˆë‹¤...\")\n",
    "    \n",
    "    # 1. DB ì—°ê²°\n",
    "    conn = dbconnect.MydbConnect('seoul_urban_lab')\n",
    "    \n",
    "    try:\n",
    "        # 2. ë°ì´í„° ì¡°íšŒ ì¿¼ë¦¬\n",
    "        sql = \"SELECT * FROM station_meta ORDER BY lineNm, stnCd\"\n",
    "        \n",
    "        # 3. ë°ì´í„°í”„ë ˆì„ìœ¼ë¡œ ë³€í™˜\n",
    "        df = pd.read_sql(sql, conn)\n",
    "        \n",
    "        if df.empty:\n",
    "            print(\"âš ï¸ í…Œì´ë¸”ì´ ë¹„ì–´ìˆìŠµë‹ˆë‹¤.\")\n",
    "            return\n",
    "\n",
    "        # 4. CSV ì €ì¥ ì„¤ì •\n",
    "        # íŒŒì¼ëª…: station_meta_backup_YYYYMMDD.csv í˜•íƒœ ê¶Œì¥\n",
    "        file_name = \"station_meta_backup.csv\"\n",
    "        \n",
    "        # utf-8-sig: ì—‘ì…€ì—ì„œ í•œê¸€ ê¹¨ì§ ë°©ì§€\n",
    "        df.to_csv(file_name, index=False, encoding='utf-8-sig')\n",
    "        \n",
    "        print(f\"\\nâœ… ë‚´ë³´ë‚´ê¸° ì™„ë£Œ!\")\n",
    "        print(f\"   - íŒŒì¼ëª…: {file_name}\")\n",
    "        print(f\"   - ì €ì¥ ê²½ë¡œ: {os.path.abspath(file_name)}\")\n",
    "        print(f\"   - ì´ ë°ì´í„°: {len(df)}ê±´\")\n",
    "        \n",
    "        # ë¯¸ë¦¬ë³´ê¸°\n",
    "        print(\"\\n[ë°ì´í„° ë¯¸ë¦¬ë³´ê¸°]\")\n",
    "        print(df.head())\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"âŒ ì˜¤ë¥˜ ë°œìƒ: {e}\")\n",
    "        \n",
    "    finally:\n",
    "        conn.close()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    export_station_meta()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hdc2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
